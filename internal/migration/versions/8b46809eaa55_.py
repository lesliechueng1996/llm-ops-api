"""empty message

Revision ID: 8b46809eaa55
Revises: dd630414aebb
Create Date: 2024-12-18 01:50:23.290272

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '8b46809eaa55'
down_revision = 'dd630414aebb'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('app_dataset_join',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), nullable=False),
    sa.Column('app_id', sa.UUID(), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.PrimaryKeyConstraint('app_id', 'dataset_id', name='pk_app_dataset_join')
    )
    with op.batch_alter_table('app_dataset_join', schema=None) as batch_op:
        batch_op.create_index('idx_app_dataset_join_app_id', ['app_id'], unique=False)
        batch_op.create_index('idx_app_dataset_join_dataset_id', ['dataset_id'], unique=False)

    op.create_table('dataset',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), nullable=False),
    sa.Column('account_id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(length=255), server_default=sa.text("''::character varying"), nullable=False),
    sa.Column('icon', sa.String(length=255), server_default=sa.text("''::character varying"), nullable=False),
    sa.Column('description', sa.Text(), server_default=sa.text("''::text"), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.PrimaryKeyConstraint('id', name='pk_dataset_id'),
    sa.UniqueConstraint('account_id', 'name', name='uk_dataset_account_id_name')
    )
    with op.batch_alter_table('dataset', schema=None) as batch_op:
        batch_op.create_index('idx_dataset_account_id', ['account_id'], unique=False)

    op.create_table('dataset_query',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('query', sa.Text(), server_default=sa.text("''::text"), nullable=False),
    sa.Column('source', sa.String(length=255), server_default=sa.text("''::character varying"), nullable=False),
    sa.Column('source_app_id', sa.UUID(), nullable=True),
    sa.Column('created_by', sa.UUID(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.PrimaryKeyConstraint('id', name='pk_dataset_query_id')
    )
    with op.batch_alter_table('dataset_query', schema=None) as batch_op:
        batch_op.create_index('idx_dataset_query_dataset_id', ['dataset_id'], unique=False)

    op.create_table('document',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), nullable=False),
    sa.Column('account_id', sa.UUID(), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('upload_file_id', sa.UUID(), nullable=False),
    sa.Column('process_rule_id', sa.UUID(), nullable=False),
    sa.Column('batch', sa.String(length=255), server_default=sa.text("''::character varying"), nullable=False),
    sa.Column('name', sa.String(length=255), server_default=sa.text("''::character varying"), nullable=False),
    sa.Column('position', sa.Integer(), server_default=sa.text('1'), nullable=False),
    sa.Column('character_count', sa.Integer(), server_default=sa.text('0'), nullable=False),
    sa.Column('token_count', sa.Integer(), server_default=sa.text('0'), nullable=False),
    sa.Column('processing_started_at', sa.DateTime(), nullable=True),
    sa.Column('parsing_completed_at', sa.DateTime(), nullable=True),
    sa.Column('splitting_completed_at', sa.DateTime(), nullable=True),
    sa.Column('indexing_completed_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('stopped_at', sa.DateTime(), nullable=True),
    sa.Column('error', sa.Text(), server_default=sa.text("''::text"), nullable=False),
    sa.Column('enabled', sa.Boolean(), server_default=sa.text('false'), nullable=False),
    sa.Column('disabled_at', sa.DateTime(), nullable=True),
    sa.Column('status', sa.String(length=255), server_default=sa.text("'waiting'::character varying"), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.PrimaryKeyConstraint('id', name='pk_document_id')
    )
    with op.batch_alter_table('document', schema=None) as batch_op:
        batch_op.create_index('idx_document_account_id', ['account_id'], unique=False)
        batch_op.create_index('idx_document_dataset_id', ['dataset_id'], unique=False)

    op.create_table('keyword_table',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('keyword_table', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.PrimaryKeyConstraint('id', name='pk_keyword_table_id')
    )
    with op.batch_alter_table('keyword_table', schema=None) as batch_op:
        batch_op.create_index('idx_keyword_table_dataset_id', ['dataset_id'], unique=False)

    op.create_table('process_rule',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), nullable=False),
    sa.Column('account_id', sa.UUID(), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('mode', sa.String(length=255), server_default=sa.text("'automic'::character varying"), nullable=False),
    sa.Column('rule', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.PrimaryKeyConstraint('id', name='pk_process_rule_id')
    )
    with op.batch_alter_table('process_rule', schema=None) as batch_op:
        batch_op.create_index('idx_process_rule_account_id', ['account_id'], unique=False)
        batch_op.create_index('idx_process_rule_dataset_id', ['dataset_id'], unique=False)

    op.create_table('segment',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), nullable=False),
    sa.Column('account_id', sa.UUID(), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('document_id', sa.UUID(), nullable=False),
    sa.Column('node_id', sa.UUID(), nullable=False),
    sa.Column('position', sa.Integer(), server_default=sa.text('1'), nullable=False),
    sa.Column('content', sa.Text(), server_default=sa.text("''::text"), nullable=False),
    sa.Column('character_count', sa.Integer(), server_default=sa.text('0'), nullable=False),
    sa.Column('token_count', sa.Integer(), server_default=sa.text('0'), nullable=False),
    sa.Column('keywords', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'[]'::jsonb"), nullable=False),
    sa.Column('hash', sa.String(length=255), server_default=sa.text("''::character varying"), nullable=False),
    sa.Column('hit_count', sa.Integer(), server_default=sa.text('0'), nullable=False),
    sa.Column('enabled', sa.Boolean(), server_default=sa.text('false'), nullable=False),
    sa.Column('disabled_at', sa.DateTime(), nullable=True),
    sa.Column('processing_started_at', sa.DateTime(), nullable=True),
    sa.Column('indexing_completed_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('stopped_at', sa.DateTime(), nullable=True),
    sa.Column('error', sa.Text(), server_default=sa.text("''::text"), nullable=False),
    sa.Column('status', sa.String(length=255), server_default=sa.text("'waiting'::character varying"), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('CURRENT_TIMESTAMP(0)'), nullable=False),
    sa.PrimaryKeyConstraint('id', name='pk_segment_id')
    )
    with op.batch_alter_table('segment', schema=None) as batch_op:
        batch_op.create_index('idx_segment_account_id', ['account_id'], unique=False)
        batch_op.create_index('idx_segment_dataset_id', ['dataset_id'], unique=False)
        batch_op.create_index('idx_segment_document_id', ['document_id'], unique=False)

    with op.batch_alter_table('api_tool_provider', schema=None) as batch_op:
        batch_op.drop_constraint('qk_api_tool_provider_account_id_name', type_='unique')
        batch_op.create_unique_constraint('uk_api_tool_provider_account_id_name', ['account_id', 'name'])

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('api_tool_provider', schema=None) as batch_op:
        batch_op.drop_constraint('uk_api_tool_provider_account_id_name', type_='unique')
        batch_op.create_unique_constraint('qk_api_tool_provider_account_id_name', ['account_id', 'name'])

    with op.batch_alter_table('segment', schema=None) as batch_op:
        batch_op.drop_index('idx_segment_document_id')
        batch_op.drop_index('idx_segment_dataset_id')
        batch_op.drop_index('idx_segment_account_id')

    op.drop_table('segment')
    with op.batch_alter_table('process_rule', schema=None) as batch_op:
        batch_op.drop_index('idx_process_rule_dataset_id')
        batch_op.drop_index('idx_process_rule_account_id')

    op.drop_table('process_rule')
    with op.batch_alter_table('keyword_table', schema=None) as batch_op:
        batch_op.drop_index('idx_keyword_table_dataset_id')

    op.drop_table('keyword_table')
    with op.batch_alter_table('document', schema=None) as batch_op:
        batch_op.drop_index('idx_document_dataset_id')
        batch_op.drop_index('idx_document_account_id')

    op.drop_table('document')
    with op.batch_alter_table('dataset_query', schema=None) as batch_op:
        batch_op.drop_index('idx_dataset_query_dataset_id')

    op.drop_table('dataset_query')
    with op.batch_alter_table('dataset', schema=None) as batch_op:
        batch_op.drop_index('idx_dataset_account_id')

    op.drop_table('dataset')
    with op.batch_alter_table('app_dataset_join', schema=None) as batch_op:
        batch_op.drop_index('idx_app_dataset_join_dataset_id')
        batch_op.drop_index('idx_app_dataset_join_app_id')

    op.drop_table('app_dataset_join')
    # ### end Alembic commands ###
